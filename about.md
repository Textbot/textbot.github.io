---
layout: page
title: About
---
## О проекте


**Что такое Textbot?**

Textbot - это технология глубинного семантического анализа и синтеза текста, а также автоматического построения баз знаний и оперирования ими.

**Могли бы Вы описать это более подробно?**

Хорошо. Начнем с баз знаний. Это условное именование моделей, содержащих знания системы. Под знаниями понимаются информационные модели окружающих нас объектов и процессов, построенных на внутреннем языке системы. Процесс оперирования знаниями принято называть мышлением. Под глубинным семантическим анализом текста понимает процесс извлечения знаний из текста, под синтезом - процесс построения текста из знаний.

**Так Вы создаете искусственный интеллект?**

Интеллект - это способность системы оперировать знаниями, выделять их текстуальной, визуальной или иной информации, а также синтезировать такую информацию из знаний. С этой точки зрения любая система, использующая технологию Textbot, является системой искусственного интеллекта.

**Используются ли Вами нейросети, большие данные, машинное обучение и другие популярные технологии?**

Список используемых нами технологий не формируется на основе моды, однако мы стараемся держать руку на пульсе и за годы своего развития технология не раз притерпевала серьезные изменения, в частности с внедрением рекуррентных нейросетей, векторных представлений слов, сжатия моделей векторным квантованием, нейросетей архитектуры Transformer (BERT / GPT-2) и др.

**Какой подход к решению Вашей задачи преобладает в мире и чем Вы отличаетесь?**

На сегодняшний преобладает нейросетевой подход с использование векторных представлений слов в качестве моделей их дистрибутивной семантики. Для задания отношений между словами или токенами и, соответственно, синтеза текста, наилучшие результаты (февраль 2019-го) показывают нейросети архитектуры Transformer, в частности сеть [BERT от Google](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) и [GPT-2 от OpenAI](https://blog.openai.com/better-language-models/). Однако проблема семантического анализа и синтеза остается не разрешенной. Причина этого кроется в том, что нейросети, обучаемые на корпусах текстов или парах "вопрос-ответ", не обладают моделью знаний, соответственно не способны накапливать знания, не могут оперировать абстрактными физическими и математическими моделями. В отличие от преобладающих решений, основой технологии Textbot является абстрактная метамодель знаний.

**Про нейросети часто говорят, что там ничего нет, кроме статистики. И что они совсем не похожи на нервную систему человека!?**

Здесь, скорее, вопрос в том, чего хотят добиться те или иные исследователи. Когда мы говорим о решении некоторой практической задачи, антропоморфность вовсе не является ключевым критерием оценки результатов. Большинство интересуют количественные показатели работы систем, будь то машинный перевод, оценка тональности или вопросно-ответная система. Если же нас интересует глобальная проблема построения системы общего искусственного интеллекта (AGI), то интерес к работам нейрофизиологов и нейробиологов очевиден хотя бы потому, что иных представлений о возможных принципах работы AGI, кроме антропоморфных, пожалуй, пока нет. Разумеется, многих исследователей интересует, почему, например, человеку не требуется прочтение десятков миллионов статей для овладения естественным языком. Та же нейросеть GPT-2 "прочитала" больше, чем все жители небольшого городка за всю жизнь, но языком по-прежнему владеет хуже.
