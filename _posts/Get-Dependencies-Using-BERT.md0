...

Рассмотрим structural-probes/run_demo.py. Здесь мы имеем методы для получения зивисимостей во входном тексте и их визуализации. 

Метод def print_tikz(args, prediction_edges, words) позволяет нам получить визуальную модель синтаксического разбора текста на языке LaTeX. 
Далее его можно отдельно сохранить, скажем, в PNG или PDF. Ниже наш пример:

![Пример выделения зависимости](/img/SyntaxDependenciesExample.png)

Аргументы:
prediction_edges - множество пар индексов, представляющих неориентированные ребра зависимостей;
words - список строк, представляющих предложение.

Метод def print_distance_image(args, words, prediction, sent_index) позволяет нам получить визуальную модель матрицы представления расстояний.

Аргументы:
words - список строк, представляющих предложение;
prediction - numpy-матрица формы (len(words), len(words)), представляющая расстояния между токенами;
sent_index - индекс предложения.

Метод def print_depth_image(args, words, prediction, sent_index) позволяет нам получить визуальную модель глубины дерева зависимостей.

Аргументы:
words - список строк, представляющих предложение;
prediction - numpy-матрица формы (len(words),), представляющая глубину каждого токена в дереве зависимостей;
sent_index - индекс предложения.

Метод def report_on_stdin(args) запускает обученный структурный зонд (structural probe), получает модель зависимостей и передает результаты 
в print_tikz, print_distance_image, print_depth_image.



Больще всего нас интересуют prediction_edges. Чтобы их получить:

predicted_edges = reporter.prims_matrix_to_edges(distance_predictions, untokenized_sent, untokenized_sent)

Данный метод вычисляет минимальное остовное дерево в матрице расстояний, рассматривая ее как матрицу смежности графа.


Интересно:
untok_tok_mapping = data.SubwordDataset.match_tokenized_to_untokenized(tokenized_sent, untokenized_sent) - здесь, судя по всему, словоформам,
полученным классическим разделителем, ставятся в соответствие один или несколько токенов, полученных токенайзером. 
При этом ВП нескольких токенов, соответствующих одному слову, ставится в соответствие их центроид. 
