---
title: Быстрый поиск в пространстве сжатых векторных представлений средствами асимметрической кластеризации Вороного
---
При работе с векторными представлениями (ВП) часто возникают проблемы с вычислительной и емкостной сложность выполения базовых операций в пространстве ВП, в частности поиска ближайших соседей. Использование классических подходов требует сравнить искомый вектор с каждым из известных векторов, мощность множества которых весьма велика (в нашем случае 1 млн.). Использование косинусной метрики или евклидова расстояния позволяют нам довольно-таки быстро осуществлять поиск ближайших соседей, однако объем затрачиваемой при этом памяти крайне велик, что приводит к зависанию обычных клиентских машин, будь-то персональных компьютеров или мобильных устройств. Так, координаты 1 млн. точек в 300-мерном пространстве занимают по крайней мере 1.2GB памяти. На выручку приходят алгоритмы сжатия ВП, позволяющие уменьшить данный объем по крайней мере в 16 раз (т.е. до 75MB). Однако классический поиск ближайших соседей на сжатых векторах не предоставляется возможным, так как для этого нам потребуется последовательно разжать каждый из 1 млн. известных векторов и сравнить его с искомым. Для разрешения данной проблемы мы воспользуемся так называемыми ячейками Вороного, позволяющими проиндексировать пространство ВП последовательным разделением его на области поиска.

В основу алгоритма индексации пространства ВП положен классический метод k-средних, используемый нами в том числе для сжатия ВП. Алгоритм предполагает использование двух гиперпараметров: мощности множества кластеров (областей поиска) ListClusterSize и коэффициента повторной кластеризации Parameter. При использовании быстрого методы быстрого поиска k-средних (MiniBatchKMeans) добавляется третий гиперпараметр: размер бетча (BatchSize). Отметим, что, пожалуй, это редкий случай, когда использование метода MiniBatchKMeans может существенно понизить качество кластеризации ввиду того, что мы переходим от 300-мерного пространства к 1-мерному. Однако, некоторым преимуществом использования данного метода является его скорость. Получив необходимое число кластеров (в нашем случае 100), мы разбили пространство ВП на 100 областей, каждая из которых обладает собственным центроидом. Нам бы хотелось, чтобы в каждую область попало по 10000 ВП или что-то около того, однако, в каждой из областей было от 100 до 66000 ВП. Именно здесь нам понадобится коэффициент повторной кластеризации.

Коэффициент повторной кластеризации позволяет оценить, насколько большое число векторов попало в тот или иной кластер (область поиска). Если число векторов в кластере превышает произведение ListClusterSize на Parameter, то данному кластеру предстоит повторное разбиение на ListClusterSize подкластеров. 
